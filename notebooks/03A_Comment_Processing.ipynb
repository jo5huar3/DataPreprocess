{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebfc172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "import os, dotenv, yaml\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "os.chdir(Path(config[\"pythonpath\"]).expanduser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecc0251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from src.preprocessing.comment_process import normalize_blanklines, strip_cryptol_comments_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1511b44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = config[\"version\"]\n",
    "\n",
    "JSONL_PATH_ORIGINAL = Path(f\"data/all_sources_verified_{VERSION}.jsonl\")\n",
    "JSONL_PATH_SLICES   = Path(f\"data/some_slices_verified_{VERSION}.jsonl\")\n",
    "\n",
    "original_df = pd.read_json(JSONL_PATH_ORIGINAL, lines=True)\n",
    "\n",
    "dfs = [original_df]\n",
    "\n",
    "if JSONL_PATH_SLICES.exists():\n",
    "    slices_df = pd.read_json(JSONL_PATH_SLICES, lines=True)\n",
    "\n",
    "    prefix = \"cryptol_slices\"\n",
    "    s = slices_df[\"filename\"].astype(str)\n",
    "    slices_df[\"filename\"] = s.where(\n",
    "        s.str.startswith(prefix + \"/\"),\n",
    "        prefix + \"/\" + s.str.lstrip(\"/\")\n",
    "    )\n",
    "\n",
    "    dfs.append(slices_df.loc[:, [\"filename\", \"filetype\", \"content\"]].copy())\n",
    "\n",
    "nomod_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367e4e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nomod_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b51b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "nocomment_df = nomod_df.copy()\n",
    "nocomment_df[\"content\"] = nocomment_df[\"content\"].apply(strip_cryptol_comments_all)\n",
    "nocomment_df[\"content\"] = nocomment_df[\"content\"].apply(normalize_blanklines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aa0f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "nocomment_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bb3484",
   "metadata": {},
   "outputs": [],
   "source": [
    "nocomment_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dad036",
   "metadata": {},
   "outputs": [],
   "source": [
    "nocomment_df[\"variant\"] = \"without_comments\"\n",
    "nocomment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ea787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OUTPUT_DIR = Path(\"data/good_syntax\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "nocomment_df.to_json(\n",
    "    OUTPUT_DIR / f\"verified_nocomments_{VERSION}.jsonl\", \n",
    "    orient=\"records\", \n",
    "    lines=True, \n",
    "    force_ascii=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445a42ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.comment_extractor import extract_strip_cry_comments\n",
    "# Create Hybrid Dataset\n",
    "out_path = Path(\"cache/GPT_comment_decisions_cache.jsonl\")\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)  # create dirs if missing\n",
    "DECISION_CACHE_PATH = \"cache/GPT_comment_decisions_cache.jsonl\"\n",
    "comment_rows = []\n",
    "dataset_rows = []\n",
    "for index, row in nomod_df.iterrows():\n",
    "    comments, file_record_ = extract_strip_cry_comments(\n",
    "        filename=row.filename,\n",
    "        content=row.content,\n",
    "        llm_model_name=\"gpt-oss:20b\",\n",
    "        decision_cache_path=DECISION_CACHE_PATH\n",
    "    )\n",
    "    comment_rows.extend(comments)\n",
    "    file_record = {\n",
    "        \"filename\": file_record_[\"filename\"],\n",
    "        \"filetype\": row.filetype,\n",
    "        \"content\": file_record_[\"content\"],\n",
    "        \"variant\": \"hybrid\"\n",
    "    }\n",
    "    dataset_rows.append(file_record)\n",
    "\n",
    "comment_df = pd.DataFrame(comment_rows)\n",
    "hybrid_df = pd.DataFrame(dataset_rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23ea39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59171748",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0147e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "HYBRID_NAME = f\"verified_hybrid_{VERSION}.jsonl\"\n",
    "COMMENT_STAT_PATH = f\"data/GPTcomment_stats_{VERSION}.jsonl\"\n",
    "\n",
    "hybrid_df.to_json(OUTPUT_DIR / HYBRID_NAME, lines=True, orient=\"records\")\n",
    "comment_df.to_json(COMMENT_STAT_PATH, lines=True, orient=\"records\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Automated_Reasoning_for_Cryptography",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
