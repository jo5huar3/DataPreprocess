{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec3da52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "import os, dotenv, yaml\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "os.chdir(Path(config[\"pythonpath\"]).expanduser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d2f870f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from src.preprocessing.quality_process import compute_file_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4302bc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Automated_Reasoning_for_Cryptography/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "Scoring rows: 31680it [01:35, 331.61it/s] \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "VERSION = config[\"version\"]\n",
    "DATA = f\"data/all_sources_verified_{VERSION}.jsonl\"\n",
    "\n",
    "MODEL_ID = \"codellama/CodeLlama-7b-Instruct-hf\"\n",
    "\n",
    "codellama_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    use_fast=True,\n",
    "    trust_remote_code=False,\n",
    ")\n",
    "\n",
    "if codellama_tokenizer.pad_token is None:\n",
    "    codellama_tokenizer.pad_token = codellama_tokenizer.eos_token\n",
    "\n",
    "# from quality_process import compute_file_metrics  # <-- uncomment and fix path\n",
    "\n",
    "results = []\n",
    "with open(DATA, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in tqdm(f, desc=\"Scoring rows\"):\n",
    "        row = json.loads(line)\n",
    "        results.append(\n",
    "            compute_file_metrics(\n",
    "                row[\"filename\"],\n",
    "                row[\"content\"],\n",
    "                model_tokenizer=codellama_tokenizer,\n",
    "            )\n",
    "        )\n",
    "\n",
    "df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "992526d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>sha1</th>\n",
       "      <th>bytes</th>\n",
       "      <th>lines</th>\n",
       "      <th>avg_line_len</th>\n",
       "      <th>max_line_len</th>\n",
       "      <th>non_ascii_ratio</th>\n",
       "      <th>binary_like</th>\n",
       "      <th>enc_total_matched</th>\n",
       "      <th>enc_max_run</th>\n",
       "      <th>enc_fraction</th>\n",
       "      <th>enc_hits_base64</th>\n",
       "      <th>enc_hits_hexbytes</th>\n",
       "      <th>enc_hits_unicode</th>\n",
       "      <th>num_tokens_lang</th>\n",
       "      <th>k_shingle</th>\n",
       "      <th>num_shingles</th>\n",
       "      <th>hexnum_ratio</th>\n",
       "      <th>num_tokens_model</th>\n",
       "      <th>junk_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cryptol/examples/AES.cry</td>\n",
       "      <td>1a40a5b760dce66cbee8b24a100c3da95850c5af</td>\n",
       "      <td>8471</td>\n",
       "      <td>237</td>\n",
       "      <td>34.75</td>\n",
       "      <td>76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1969</td>\n",
       "      <td>5</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.003047</td>\n",
       "      <td>4471</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cryptol/examples/width.cry</td>\n",
       "      <td>6fcd12515c7bdf141d925f4c06dfa311b96c353d</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cryptol/examples/splitAt.cry</td>\n",
       "      <td>816e7cd6994a469bc9fb88ded8fea4f463a59e40</td>\n",
       "      <td>108</td>\n",
       "      <td>10</td>\n",
       "      <td>9.90</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cryptol/examples/AE.cry</td>\n",
       "      <td>05483796c6a8a4760cd335120b09c67c7ef1db78</td>\n",
       "      <td>2372</td>\n",
       "      <td>86</td>\n",
       "      <td>26.59</td>\n",
       "      <td>77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>446</td>\n",
       "      <td>5</td>\n",
       "      <td>442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>872</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cryptol/examples/Cipher.cry</td>\n",
       "      <td>0a59fbdcb5a178868f785173a719c45172e015e7</td>\n",
       "      <td>283</td>\n",
       "      <td>12</td>\n",
       "      <td>22.67</td>\n",
       "      <td>69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>105</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       filename                                      sha1  \\\n",
       "0      cryptol/examples/AES.cry  1a40a5b760dce66cbee8b24a100c3da95850c5af   \n",
       "1    cryptol/examples/width.cry  6fcd12515c7bdf141d925f4c06dfa311b96c353d   \n",
       "2  cryptol/examples/splitAt.cry  816e7cd6994a469bc9fb88ded8fea4f463a59e40   \n",
       "3       cryptol/examples/AE.cry  05483796c6a8a4760cd335120b09c67c7ef1db78   \n",
       "4   cryptol/examples/Cipher.cry  0a59fbdcb5a178868f785173a719c45172e015e7   \n",
       "\n",
       "   bytes  lines  avg_line_len  max_line_len  non_ascii_ratio  binary_like  \\\n",
       "0   8471    237         34.75            76              0.0        False   \n",
       "1     31      3          9.67            22              0.0        False   \n",
       "2    108     10          9.90            33              0.0        False   \n",
       "3   2372     86         26.59            77              0.0        False   \n",
       "4    283     12         22.67            69              0.0        False   \n",
       "\n",
       "   enc_total_matched  enc_max_run  enc_fraction  enc_hits_base64  \\\n",
       "0                  0            0           0.0                0   \n",
       "1                  0            0           0.0                0   \n",
       "2                  0            0           0.0                0   \n",
       "3                  0            0           0.0                0   \n",
       "4                  0            0           0.0                0   \n",
       "\n",
       "   enc_hits_hexbytes  enc_hits_unicode  num_tokens_lang  k_shingle  \\\n",
       "0                  0                 0             1969          5   \n",
       "1                  0                 0               15          5   \n",
       "2                  0                 0               68          5   \n",
       "3                  0                 0              446          5   \n",
       "4                  0                 0               37          5   \n",
       "\n",
       "   num_shingles  hexnum_ratio  num_tokens_model  junk_path  \n",
       "0          1965      0.003047              4471      False  \n",
       "1            11      0.000000                18      False  \n",
       "2            64      0.000000                74      False  \n",
       "3           442      0.000000               872      False  \n",
       "4            33      0.000000               105      False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a03ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StarCoder-like thresholds (tune if needed)\n",
    "MAX_BYTES         = 200_000\n",
    "MAX_NONASCII      = 0.20\n",
    "ENC_MAX_RUN_CHARS = 1024\n",
    "ENC_MAX_FRACTION  = 0.50\n",
    "MAX_LINES_TOTAL   = 100_000\n",
    "MAX_LINE_AVG_LEN  = 100\n",
    "MAX_LINE_MAX_LEN  = 1_000\n",
    "MIN_TOKENS_LANG   = 40      # language-token gate (Cryptol tokenizer)\n",
    "MAX_TOKENS_LANG   = 10_000  # optional upper bound\n",
    "MIN_TOKENS_MODEL  = 40      # only if youâ€™ve populated num_tokens_model\n",
    "MAX_HEXNUM_RATIO  = 0.20\n",
    "\n",
    "\n",
    "# --- exact dedup (keep first occurrence of each sha1) ---\n",
    "# mark duplicates (True means \"is duplicate\" => drop later)\n",
    "dup_mask = df.duplicated(subset=[\"sha1\"], keep=\"first\")\n",
    "\n",
    "# --- encoded data (StarCoder) ---\n",
    "enc_mask = (df[\"enc_max_run\"] > ENC_MAX_RUN_CHARS) | (df[\"enc_fraction\"] > ENC_MAX_FRACTION)\n",
    "\n",
    "# --- long-line filters (StarCoder) ---\n",
    "longline_mask = (\n",
    "    (df[\"lines\"] > MAX_LINES_TOTAL) |\n",
    "    (df[\"avg_line_len\"] > MAX_LINE_AVG_LEN) |\n",
    "    (df[\"max_line_len\"] > MAX_LINE_MAX_LEN)\n",
    ")\n",
    "\n",
    "# --- binary-like content ---\n",
    "binary_mask = df[\"binary_like\"].fillna(False)\n",
    "\n",
    "# --- non-ascii density ---\n",
    "nonascii_mask = df[\"non_ascii_ratio\"].fillna(0) > MAX_NONASCII\n",
    "\n",
    "# --- size guardrail (bytes) ---\n",
    "bytes_mask = df[\"bytes\"].fillna(0) > MAX_BYTES\n",
    "\n",
    "# --- language-token bounds ---\n",
    "lang_small_mask = df[\"num_tokens_lang\"].fillna(0) < MIN_TOKENS_LANG\n",
    "lang_large_mask = df[\"num_tokens_lang\"].fillna(0) > MAX_TOKENS_LANG\n",
    "\n",
    "# --- shingles exist (needed for Jaccard) ---\n",
    "no_shingles_mask = df[\"num_shingles\"].fillna(0) <= 0\n",
    "\n",
    "# --- numeric/hex blob concentration ---\n",
    "hexnum_mask = df[\"hexnum_ratio\"].fillna(0) > MAX_HEXNUM_RATIO\n",
    "\n",
    "# --- model-token gate (only apply where available) ---\n",
    "if \"num_tokens_model\" in df.columns:\n",
    "    model_small_mask = df[\"num_tokens_model\"].fillna(np.inf) < MIN_TOKENS_MODEL\n",
    "else:\n",
    "    model_small_mask = pd.Series(False, index=df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c71bc7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all hard-drop reasons\n",
    "drop_mask = (\n",
    "    dup_mask |\n",
    "    enc_mask |\n",
    "    longline_mask |\n",
    "    binary_mask |\n",
    "    nonascii_mask |\n",
    "    bytes_mask |\n",
    "    lang_small_mask |\n",
    "    lang_large_mask |\n",
    "    no_shingles_mask |\n",
    "    hexnum_mask |\n",
    "    model_small_mask\n",
    ")\n",
    "\n",
    "# Optional: compute a human-readable fail reason (first rule that tripped)\n",
    "def first_reason(i):\n",
    "    if dup_mask.iat[i]:          return \"exact_duplicate\"\n",
    "    if enc_mask.iat[i]:          return \"encoded_data\"\n",
    "    if longline_mask.iat[i]:     return \"long_lines\"\n",
    "    if binary_mask.iat[i]:       return \"binary_like\"\n",
    "    if nonascii_mask.iat[i]:     return \"too_much_nonascii\"\n",
    "    if bytes_mask.iat[i]:        return \"too_large_bytes\"\n",
    "    if lang_small_mask.iat[i]:   return \"too_few_lang_tokens\"\n",
    "    if lang_large_mask.iat[i]:   return \"too_many_lang_tokens\"\n",
    "    if no_shingles_mask.iat[i]:  return \"no_shingles\"\n",
    "    if hexnum_mask.iat[i]:       return \"hexnum_blob\"\n",
    "    if model_small_mask.iat[i]:  return \"too_few_model_tokens\"\n",
    "    return \"ok\"\n",
    "\n",
    "df = df.copy()\n",
    "df[\"quality_ok\"] = ~drop_mask\n",
    "df[\"fail_reason\"] = [first_reason(i) for i in range(len(df))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a954212e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>filetype</th>\n",
       "      <th>content</th>\n",
       "      <th>n_imports_original</th>\n",
       "      <th>n_imports_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cryptol/examples/AES.cry</td>\n",
       "      <td>cry</td>\n",
       "      <td>// Cryptol AES Implementation\\n// Copyright (c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cryptol/examples/splitAt.cry</td>\n",
       "      <td>cry</td>\n",
       "      <td>x = [1,2,3,4] : [_][8]\\n\\ny = (splitAt x) : ([...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cryptol/examples/AE.cry</td>\n",
       "      <td>cry</td>\n",
       "      <td>// WORK IN PROGRESS\\n\\n/*\\nImplementation of t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cryptol/examples/xor_cipher.cry</td>\n",
       "      <td>cry</td>\n",
       "      <td>encrypt : {a}(fin a) =&gt; [8] -&gt; [a][8] -&gt; [a][8...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cryptol/examples/zero_weird.cry</td>\n",
       "      <td>cry</td>\n",
       "      <td>x : {a}() =&gt; a -&gt; [16]\\nx v = zero v \\n\\nprope...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          filename filetype  \\\n",
       "0         cryptol/examples/AES.cry      cry   \n",
       "1     cryptol/examples/splitAt.cry      cry   \n",
       "2          cryptol/examples/AE.cry      cry   \n",
       "3  cryptol/examples/xor_cipher.cry      cry   \n",
       "4  cryptol/examples/zero_weird.cry      cry   \n",
       "\n",
       "                                             content  n_imports_original  \\\n",
       "0  // Cryptol AES Implementation\\n// Copyright (c...                 NaN   \n",
       "1  x = [1,2,3,4] : [_][8]\\n\\ny = (splitAt x) : ([...                 NaN   \n",
       "2  // WORK IN PROGRESS\\n\\n/*\\nImplementation of t...                 NaN   \n",
       "3  encrypt : {a}(fin a) => [8] -> [a][8] -> [a][8...                 NaN   \n",
       "4  x : {a}() => a -> [16]\\nx v = zero v \\n\\nprope...                 NaN   \n",
       "\n",
       "   n_imports_final  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedup_cols = [\n",
    "    \"filename\", \"sha1\",\n",
    "    # size/lines\n",
    "    \"bytes\", \"lines\", \"avg_line_len\", \"max_line_len\",\n",
    "    # content/encoding\n",
    "    \"non_ascii_ratio\", \"binary_like\",\n",
    "    \"enc_total_matched\", \"enc_max_run\", \"enc_fraction\",\n",
    "    \"enc_hits_base64\", \"enc_hits_hexbytes\", \"enc_hits_unicode\",\n",
    "    # tokens/shingles\n",
    "    \"num_tokens_lang\", \"k_shingle\", \"num_shingles\", \"hexnum_ratio\",\n",
    "    # model tokens (optional)\n",
    "    \"num_tokens_model\",\n",
    "    # path heuristic & status\n",
    "    \"quality_ok\", \"fail_reason\",\n",
    "]\n",
    "\n",
    "candidate_df = df.loc[df[\"quality_ok\"], dedup_cols].reset_index(drop=True)\n",
    "similar_process_df = pd.read_json(DATA, lines=True)\n",
    "similar_process_df = similar_process_df[similar_process_df['filename'].isin(candidate_df['filename'])].reset_index(drop=True)\n",
    "put_back_path = Path(\"data/dropped/files_to_put_back.csv\")\n",
    "'''\n",
    "if put_back_path.exists():\n",
    "    put_back_set = pd.read_csv(put_back_path)\n",
    "    put_back_filenames = set(put_back_set[\"filename\"].dropna().tolist())\n",
    "else:\n",
    "    put_back_filenames = set()\n",
    "\n",
    "for fname in put_back_filenames:\n",
    "    if fname in df['filename'].values:\n",
    "        candidate_df = pd.concat([candidate_df, df[df['filename'] == fname][dedup_cols]], ignore_index=True)\n",
    "        candidate_df.loc[candidate_df['filename'] == fname, 'quality_ok'] = True\n",
    "        '''\n",
    "similar_process_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0156792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[summary] total: 31680\n",
      "[summary] kept : 1129\n",
      "[summary] dropped: 30551\n",
      "[summary] drop reasons:\n",
      "fail_reason\n",
      "exact_duplicate         16354\n",
      "encoded_data             7649\n",
      "too_few_lang_tokens      6518\n",
      "hexnum_blob                18\n",
      "too_many_lang_tokens        5\n",
      "too_large_bytes             4\n",
      "long_lines                  2\n",
      "too_few_model_tokens        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"[summary] total:\", len(df))\n",
    "print(\"[summary] kept :\", int(df[\"quality_ok\"].sum()))\n",
    "print(\"[summary] dropped:\", int((~df[\"quality_ok\"]).sum()))\n",
    "print(\"[summary] drop reasons:\")\n",
    "print(df.loc[~df[\"quality_ok\"], \"fail_reason\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c12ceeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31680 entries, 0 to 31679\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   filename           31680 non-null  object \n",
      " 1   sha1               31680 non-null  object \n",
      " 2   bytes              31680 non-null  int64  \n",
      " 3   lines              31680 non-null  int64  \n",
      " 4   avg_line_len       31680 non-null  float64\n",
      " 5   max_line_len       31680 non-null  int64  \n",
      " 6   non_ascii_ratio    31680 non-null  float64\n",
      " 7   binary_like        31680 non-null  bool   \n",
      " 8   enc_total_matched  31680 non-null  int64  \n",
      " 9   enc_max_run        31680 non-null  int64  \n",
      " 10  enc_fraction       31680 non-null  float64\n",
      " 11  enc_hits_base64    31680 non-null  int64  \n",
      " 12  enc_hits_hexbytes  31680 non-null  int64  \n",
      " 13  enc_hits_unicode   31680 non-null  int64  \n",
      " 14  num_tokens_lang    31680 non-null  int64  \n",
      " 15  k_shingle          31680 non-null  int64  \n",
      " 16  num_shingles       31680 non-null  int64  \n",
      " 17  hexnum_ratio       31680 non-null  float64\n",
      " 18  num_tokens_model   31680 non-null  int64  \n",
      " 19  junk_path          31680 non-null  bool   \n",
      " 20  quality_ok         31680 non-null  bool   \n",
      " 21  fail_reason        31680 non-null  object \n",
      "dtypes: bool(3), float64(4), int64(12), object(3)\n",
      "memory usage: 4.7+ MB\n"
     ]
    }
   ],
   "source": [
    "dropped = df[df[\"quality_ok\"] == False].copy().reset_index(drop=True)\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9846b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#review_data_set = df[~df['fail_reason'].isin(['ok', 'exact_duplicate'])].copy().reset_index(drop=True)\n",
    "#out_path = Path(f\"data/dropped/review_files_{VARIATION}_{VERSION}.csv\")\n",
    "#out_path.parent.mkdir(parents=True, exist_ok=True)  # create dirs if missing\n",
    "#review_data_set.to_csv(out_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec151e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] ==== Starting MinHash/LSH over DataFrame ====\n",
      "[info] params: K_SHINGLE=5, NUM_PERM=512, LSH_THRESHOLD=0.7\n",
      "[info] loaded 1129 files from candidate_df\n",
      "[info] files indexed   : 1129\n",
      "[diag] total candidate pairs: 935\n",
      "[diag] pairs with jaccard >= 0.7: 670\n",
      "[warn] parquet save failed (Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\n",
      "A suitable version of pyarrow or fastparquet is required for parquet support.\n",
      "Trying to import the above resulted in these errors:\n",
      " - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n",
      " - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.); CSVs were still written to minhash_outputs/\n",
      "\n",
      "[info] ==== MinHash/LSH run summary ====\n",
      "[info] files loaded  : 1129\n",
      "[info] files indexed : 1129\n",
      "[info] files with 0 shingles (tokens < 5): 0\n",
      "[info] candidate pairs (from LSH) : 935\n",
      "[info] pairs with Jaccard >= 0.60: 751\n",
      "[info] pairs with Jaccard >= 0.70: 670\n",
      "[info] pairs with Jaccard >= 0.80: 429\n",
      "[info] pairs with Jaccard >= 0.85: 317\n",
      "[info] pairs with Jaccard >= 0.90: 220\n",
      "[info] avg Jaccard (candidates)  : 0.7694\n",
      "[info] max Jaccard               : 1.0000\n",
      "[info] min Jaccard               : 0.4104\n",
      "\n",
      "[info] top pairs:\n",
      "                                                                                                          a                                                                                                           b  jaccard  a_shingles  b_shingles  union_shingles  intersect_shingles\n",
      "                                                          cryptol/docs/ProgrammingCryptol/enigma/Finite.cry                                 cryptol_slices/cryptol/docs/ProgrammingCryptol/enigma/Finite_002_sumInf.cry 1.000000          43          43              43                  43\n",
      "                                                                        cryptol/examples/funstuff/Coins.cry                                           cryptol_slices/cryptol/examples/funstuff/Coins_002_coinPuzzle.cry 1.000000          99          99              99                  99\n",
      "                                                    cryptol_slices/cryptol-specs/Common/utils_002_while.cry   cryptol_slices/cryptol-specs/Primitive/Asymmetric/Signature/FALCON/1.2/falcon_parameterized_005_while.cry 1.000000          36          36              36                  36\n",
      "                                                                                cryptol/examples/demote.cry                                                            cryptol_slices/cryptol/examples/demote_003_y.cry 1.000000          36          36              36                  36\n",
      "                                                  cryptol_slices/cryptol-specs/Common/utils_003_dowhile.cry cryptol_slices/cryptol-specs/Primitive/Asymmetric/Signature/FALCON/1.2/falcon_parameterized_007_dowhile.cry 1.000000          59          59              59                  59\n",
      "                                cryptol_slices/cryptol/docs/ProgrammingCryptol/enigma/Enigma_025_enigma.cry                                cryptol_slices/cryptol/docs/ProgrammingCryptol/enigma/Enigma_027_dEnigma.cry 0.995169         618         621             621                 618\n",
      "cryptol_slices/cryptol-specs/Primitive/Symmetric/Cipher/Stream/ZUC_046_ZUC_isResistantToCollisionAttack.cry                              cryptol_slices/cryptol/bench/data/ZUC_046_ZUC_isResistantToCollisionAttack.cry 0.995042        2012        2012            2017                2007\n",
      "                    cryptol_slices/cryptol-specs/Primitive/Symmetric/Cipher/Stream/ZUC_039_WorkingStage.cry                                                  cryptol_slices/cryptol/bench/data/ZUC_039_WorkingStage.cry 0.994970        1983        1983            1988                1978\n",
      "                cryptol_slices/cryptol-specs/Primitive/Symmetric/Cipher/Block/KATAN_067_katantanEncrypt.cry                    cryptol_slices/cryptol-specs/Primitive/Symmetric/Cipher/Block/KATAN_091_katantan64_2.cry 0.994678        1869        1879            1879                1869\n",
      "                cryptol_slices/cryptol-specs/Primitive/Symmetric/Cipher/Block/KATAN_067_katantanEncrypt.cry                    cryptol_slices/cryptol-specs/Primitive/Symmetric/Cipher/Block/KATAN_090_katantan64_1.cry 0.994678        1869        1879            1879                1869\n",
      "                        cryptol_slices/cryptol-specs/Primitive/Symmetric/Cipher/Block/KATAN_086_tests64.cry                       cryptol_slices/cryptol-specs/Primitive/Symmetric/Cipher/Block/KATAN_087_testsPass.cry 0.994138        2039        2043            2047                2035\n",
      "                   cryptol_slices/cryptol-specs/Primitive/Symmetric/Cipher/Block/KATAN_036_katanEncrypt.cry                       cryptol_slices/cryptol-specs/Primitive/Symmetric/Cipher/Block/KATAN_089_katan64_2.cry 0.989785         969         979             979                 969\n",
      "                   cryptol_slices/cryptol-specs/Primitive/Symmetric/Cipher/Block/KATAN_036_katanEncrypt.cry                       cryptol_slices/cryptol-specs/Primitive/Symmetric/Cipher/Block/KATAN_088_katan64_1.cry 0.989785         969         979             979                 969\n",
      "                   cryptol_slices/cryptol-specs/Primitive/Symmetric/Cipher/Block/KATAN_090_katantan64_1.cry                    cryptol_slices/cryptol-specs/Primitive/Symmetric/Cipher/Block/KATAN_091_katantan64_2.cry 0.989412        1879        1879            1889                1869\n",
      "                 cryptol_slices/cryptol-specs/Primitive/Symmetric/Cipher/Stream/ZUC_044_ZUC_TestVectors.cry                                               cryptol_slices/cryptol/bench/data/ZUC_044_ZUC_TestVectors.cry 0.988693        2200        2197            2211                2186\n",
      "                cryptol_slices/cryptol-specs/Primitive/Symmetric/Cipher/Block/KATAN_067_katantanEncrypt.cry               cryptol_slices/cryptol-specs/Primitive/Symmetric/Cipher/Block/KATAN_069_katantanEncrypt64.cry 0.988366        1869        1891            1891                1869\n",
      "                               cryptol_slices/cryptol-specs/Primitive/Symmetric/Cipher/Stream/ZUC_015_S.cry                         cryptol_slices/cryptol-specs/Primitive/Symmetric/Cipher/Stream/ZUC_016_example8.cry 0.986051        1135        1143            1147                1131\n",
      "                                                                                 cryptol/bench/data/ZUC.cry                                    cryptol/examples/cryptol-specs/Primitive/Symmetric/Cipher/Stream/ZUC.cry 0.985669        2487        2501            2512                2476\n",
      "                    cryptol_slices/cryptol-specs/Primitive/Symmetric/Cipher/Stream/ZUC_039_WorkingStage.cry cryptol_slices/cryptol-specs/Primitive/Symmetric/Cipher/Stream/ZUC_046_ZUC_isResistantToCollisionAttack.cry 0.985586        1983        2012            2012                1983\n",
      "                                                 cryptol_slices/cryptol/bench/data/ZUC_039_WorkingStage.cry                              cryptol_slices/cryptol/bench/data/ZUC_046_ZUC_isResistantToCollisionAttack.cry 0.985586        1983        2012            2012                1983\n",
      "[info] saved hash signatures JSONL: minhash_outputs/minhash_signatures.jsonl\n"
     ]
    }
   ],
   "source": [
    "from src.preprocessing.similiar_process import run_from_dataframe\n",
    "\n",
    "# candidate_df must have an absolute-path 'filename' column.\n",
    "df_files, df_pairs, similar_files = run_from_dataframe(\n",
    "    similar_process_df,\n",
    "    filename_col=\"filename\",\n",
    "    content_col=\"content\",\n",
    "    out_dir=\"minhash_outputs\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55aa4783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>num_shingles</th>\n",
       "      <th>num_perm</th>\n",
       "      <th>k_shingle</th>\n",
       "      <th>minhash_hashvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cryptol-specs/Primitive/Symmetric/Cipher/Block...</td>\n",
       "      <td>240</td>\n",
       "      <td>155</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>[35024350, 8568550, 91351199, 32302987, 488898...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cryptol-specs/Primitive/Symmetric/Cipher/Block...</td>\n",
       "      <td>95</td>\n",
       "      <td>58</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>[47629316, 411531329, 115630586, 226486299, 48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cryptol-specs/Primitive/Symmetric/MAC/HMAC/Int...</td>\n",
       "      <td>81</td>\n",
       "      <td>75</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>[57770824, 40571396, 18548176, 59333592, 30374...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cryptol-specs/Primitive/Symmetric/MAC/HMAC/Spe...</td>\n",
       "      <td>316</td>\n",
       "      <td>230</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>[9231033, 9956168, 37811696, 28847082, 3037481...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cryptol/bench/data/SHA512.cry</td>\n",
       "      <td>830</td>\n",
       "      <td>740</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>[1284583, 6097570, 2750808, 1988048, 3200279, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  num_tokens  \\\n",
       "0  cryptol-specs/Primitive/Symmetric/Cipher/Block...         240   \n",
       "1  cryptol-specs/Primitive/Symmetric/Cipher/Block...          95   \n",
       "2  cryptol-specs/Primitive/Symmetric/MAC/HMAC/Int...          81   \n",
       "3  cryptol-specs/Primitive/Symmetric/MAC/HMAC/Spe...         316   \n",
       "4                      cryptol/bench/data/SHA512.cry         830   \n",
       "\n",
       "   num_shingles  num_perm  k_shingle  \\\n",
       "0           155       512          5   \n",
       "1            58       512          5   \n",
       "2            75       512          5   \n",
       "3           230       512          5   \n",
       "4           740       512          5   \n",
       "\n",
       "                                  minhash_hashvalues  \n",
       "0  [35024350, 8568550, 91351199, 32302987, 488898...  \n",
       "1  [47629316, 411531329, 115630586, 226486299, 48...  \n",
       "2  [57770824, 40571396, 18548176, 59333592, 30374...  \n",
       "3  [9231033, 9956168, 37811696, 28847082, 3037481...  \n",
       "4  [1284583, 6097570, 2750808, 1988048, 3200279, ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aefc8729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] clusters formed   : 782\n",
      "[info] kept files        : 782\n",
      "[info] dropped files     : 347\n",
      "[info] wrote keep/drop/cluster CSVs to minhash_outputs/\n"
     ]
    }
   ],
   "source": [
    "from src.preprocessing.cluster_process import run_clustering\n",
    "\n",
    "# If you already have df_files/df_pairs in memory:\n",
    "df_keep, df_drop, df_clusters = run_clustering(\n",
    "    df_files=df_files,          # from similiar_process\n",
    "    df_pairs=df_pairs,          # from similiar_process\n",
    "    jaccard_keep_threshold=0.70,\n",
    "    out_dir=\"minhash_outputs\",\n",
    "    content_lookup=None,        # or {filename: raw_text} if you want text-derived penalties\n",
    "    save_outputs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f22bb5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIATION = \"nomods\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d94f0fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df[df['filename'].isin(df_keep['filename'].tolist())].copy()\n",
    "df.loc[\n",
    "    df['filename'].isin(df_drop['filename'].tolist()),\n",
    "    'quality_ok'\n",
    "    ] = False\n",
    "df.loc[\n",
    "    df['filename'].isin(df_drop['filename'].tolist()),\n",
    "    'fail_reason'\n",
    "    ] = 'similiar_file_exists'\n",
    "\n",
    "dropped = df[~df['filename'].isin(dataset['filename'].tolist())].copy().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00b19640",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropped.to_csv(f\"data/dropped/{VARIATION}_dropped_files_{VERSION}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec52c0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "verified_files = set(dataset[\"filename\"].unique())\n",
    "\n",
    "all_files_df = pd.read_json(DATA, lines=True)\n",
    "all_files_filtered_df = all_files_df[all_files_df[\"filename\"].isin(verified_files)].reset_index(drop=True)\n",
    "out_path = Path(f\"data/training_datasets/verified_{VARIATION}_{VERSION}.jsonl\")\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)  # create dirs if missing\n",
    "all_files_filtered_df.to_json(out_path, lines=True, orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6c3b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"data/{VARIATION}_file_metrics_{VERSION}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Automated_Reasoning_for_Cryptography",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
